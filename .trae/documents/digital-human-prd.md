# MetaHuman 交互 Demo/SDK PRD（精简版）

## 1. 产品定位

本项目是一个“数字人交互 Demo/SDK”，用于展示与验证：

- Web 端 3D 数字人渲染与基础动画
- 语音交互（TTS/ASR，基于 Web Speech API）
- 视觉镜像（摄像头 + MediaPipe，表情/头部动作映射）
- 后端对话大脑（FastAPI + OpenAI，可配置；无 key 时自动回退 Mock）

## 2. 目标用户

- 需要快速演示“数字人交互闭环”的开发者/方案人员
- 需要基于现有代码二次开发接入业务场景的团队

## 3. 非目标（当前版本明确不做）

- 用户注册/登录/权限管理
- 模型管理后台（上传/编辑/审核/发布）
- 行为编排编辑器（时间轴、复杂触发条件）
- 平台化部署管理与多租户能力

## 4. 核心体验与关键路径

### 4.1 关键路径 A：文本对话驱动数字人

1. 用户打开页面（默认 Advanced 页）
2. 输入文本并发送
3. 系统请求后端 `/v1/chat` 获取 `{ replyText, emotion, action }`
4. 数字人表现：表情/动作同步更新；未静音时播放 TTS

### 4.2 关键路径 B：语音输入驱动对话

1. 用户点击录音
2. ASR 得到文本
3. 走与文本输入相同的 `/v1/chat` 链路

### 4.3 关键路径 C：视觉镜像

1. 用户授权摄像头
2. 面板展示摄像头画面与识别到的情绪/动作
3. 数字人表情/动作随识别结果变化

## 5. 功能清单（以当前实现为准）

- 3D：渲染与基础交互（旋转、环境、加载状态）
- 音频：
  - 语音合成（TTS）
  - 语音识别（ASR）
  - 静音/录音状态与 UI 同步
- 对话：
  - 统一接口：`POST /v1/chat`
  - 有 key 走 OpenAI；无 key 或异常走 Mock
- 视觉：
  - FaceMesh / Pose 推理
  - 表情与头部动作映射

## 6. 配置与运行

### 6.1 前端

- `VITE_API_BASE_URL`：后端地址（默认 `http://localhost:8000`）

### 6.2 后端

- `OPENAI_API_KEY`：可选；不配置则使用 Mock
- `OPENAI_MODEL`：可选；默认 `gpt-3.5-turbo`
- `OPENAI_BASE_URL`：可选；支持传入域名/`/v1`/完整路径，后端会规范化为 `.../v1/chat/completions`
